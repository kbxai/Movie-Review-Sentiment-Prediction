{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":125009,"databundleVersionId":14733181,"sourceType":"competition"}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Assignment 3 - Movie Review Sentiment Prediction\n\n## Assignment Description\nIn this assignment, your task is to predict the sentiment of the given movie reviews. You will be provided with a training dataset and a test dataset. The labels for the test dataset will remain hidden, and your task is to submit predictions for the same. The assignment will be conducted on the Kaggle Platform.\n\n## Instructions\n1. Use the following link to join the competition: [Kaggle Competition](https://www.kaggle.com/t/bdfe59603f7a49819e1888c5b35cadb5)\n2. After joining the competition, go to the Code tab and create a New Notebook.\n3. Use this Notebook to make model submissions, and the performance of the model will be reflected in the leaderboard.\n4. Refer to the rubrics provided below for the peer review to understand the minimum requirements in the notebook.\n5. The deadline for the assignment is **Dec 11, 2025**.\n\n## Peer Review Rubrics Checklist\n- [x] Identify data types of different columns\n- [x] Present descriptive statistics of numerical columns\n- [x] Identify and handle the missing values\n- [x] Identify and handle duplicates\n- [x] Identify and handle outliers\n- [x] Present at least three visualizations and provide insights\n- [x] Scale Numerical features and Encode Categorical features\n- [x] Model Building (at least 7 models)\n- [x] Hyperparameter Tuning on any 3 of the models\n- [x] Comparison of model performances","metadata":{"execution":{"iopub.status.busy":"2025-12-04T11:59:40.468851Z","iopub.execute_input":"2025-12-04T11:59:40.469109Z","iopub.status.idle":"2025-12-04T11:59:40.479442Z","shell.execute_reply.started":"2025-12-04T11:59:40.469088Z","shell.execute_reply":"2025-12-04T11:59:40.478102Z"}}},{"cell_type":"code","source":"# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\nfrom collections import Counter\n\n# Download NLTK data\ntry:\n    nltk.data.find('corpora/stopwords')\n    nltk.data.find('corpora/wordnet')\n    nltk.data.find('sentiment/vader_lexicon')\nexcept LookupError:\n    nltk.download('stopwords')\n    nltk.download('wordnet')\n    nltk.download('omw-1.4')\n    nltk.download('vader_lexicon')\n\n# Set plot style\nsns.set(style=\"whitegrid\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:00:03.583208Z","iopub.execute_input":"2025-12-04T12:00:03.583707Z","iopub.status.idle":"2025-12-04T12:00:12.200669Z","shell.execute_reply.started":"2025-12-04T12:00:03.583681Z","shell.execute_reply":"2025-12-04T12:00:12.200056Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Data\n# Note: Adjust the paths if running locally or on Kaggle\ntry:\n    train = pd.read_csv('/kaggle/input/mlp-term-3-2025-kaggle-assignment-3/train.csv')\n    test = pd.read_csv('/kaggle/input/mlp-term-3-2025-kaggle-assignment-3/test.csv')\n    submission = pd.read_csv('/kaggle/input/mlp-term-3-2025-kaggle-assignment-3/sample_submission.csv')\n    print(\"Data loaded from Kaggle directory.\")\nexcept FileNotFoundError:\n    # Fallback for local testing if files are in the same directory\n    try:\n        train = pd.read_csv('train.csv')\n        test = pd.read_csv('test.csv')\n        submission = pd.read_csv('sample_submission.csv')\n        print(\"Data loaded from local directory.\")\n    except FileNotFoundError:\n        print(\"Error: Data files not found. Please ensure train.csv and test.csv are available.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:00:12.201859Z","iopub.execute_input":"2025-12-04T12:00:12.202568Z","iopub.status.idle":"2025-12-04T12:00:12.249019Z","shell.execute_reply.started":"2025-12-04T12:00:12.202547Z","shell.execute_reply":"2025-12-04T12:00:12.248465Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Rubric Step 1: Identify Data Types\nWe will examine the data types of the columns in the training dataset.","metadata":{}},{"cell_type":"code","source":"print(\"Training Data Info:\")\nprint(train.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:00:12.249752Z","iopub.execute_input":"2025-12-04T12:00:12.249991Z","iopub.status.idle":"2025-12-04T12:00:12.272046Z","shell.execute_reply.started":"2025-12-04T12:00:12.249974Z","shell.execute_reply":"2025-12-04T12:00:12.271516Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Observation:** The output above shows the data types for each column (e.g., `int64`, `float64`, `object`).","metadata":{}},{"cell_type":"markdown","source":"## Rubric Step 2: Descriptive Statistics\nWe will look at the descriptive statistics (mean, median, min, max, etc.) for the numerical columns.","metadata":{}},{"cell_type":"code","source":"print(\"Descriptive Statistics:\")\nprint(train.describe())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:00:12.273673Z","iopub.execute_input":"2025-12-04T12:00:12.274159Z","iopub.status.idle":"2025-12-04T12:00:12.293602Z","shell.execute_reply.started":"2025-12-04T12:00:12.274143Z","shell.execute_reply":"2025-12-04T12:00:12.293001Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Rubric Step 3: Identify and Handle Missing Values\nWe will check for missing values and handle them appropriately (imputation or dropping).","metadata":{}},{"cell_type":"code","source":"print(\"Missing values before handling:\")\nprint(train.isnull().sum())\n\n# Define numerical columns\nnum_cols = ['feature_1', 'feature_2', 'feature_3']\n\n# Impute numerical columns with median\nimputer = SimpleImputer(strategy='median')\ntrain[num_cols] = imputer.fit_transform(train[num_cols])\ntest[num_cols] = imputer.transform(test[num_cols])\n\n# Drop rows with missing target ('sentiment') or text ('phrase') in train\ntrain.dropna(subset=['phrase', 'sentiment'], inplace=True)\n\n# Fill missing phrases in test with empty string\ntest['phrase'] = test['phrase'].fillna('')\n\nprint(\"\\nMissing values after handling:\")\nprint(train.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:00:12.294153Z","iopub.execute_input":"2025-12-04T12:00:12.294347Z","iopub.status.idle":"2025-12-04T12:00:12.312301Z","shell.execute_reply.started":"2025-12-04T12:00:12.294333Z","shell.execute_reply":"2025-12-04T12:00:12.311679Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Rubric Step 4: Identify and Handle Duplicates\nWe will check for and remove duplicate rows to ensure data quality.","metadata":{}},{"cell_type":"code","source":"initial_len = len(train)\ntrain.drop_duplicates(inplace=True)\nprint(f\"Dropped {initial_len - len(train)} duplicate rows.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:00:12.312985Z","iopub.execute_input":"2025-12-04T12:00:12.313238Z","iopub.status.idle":"2025-12-04T12:00:12.323540Z","shell.execute_reply.started":"2025-12-04T12:00:12.313200Z","shell.execute_reply":"2025-12-04T12:00:12.322892Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Rubric Step 5: Identify and Handle Outliers\nWe will identify outliers using the IQR method but will retain them as they might contain valuable information for sentiment analysis.","metadata":{}},{"cell_type":"code","source":"print(\"Outlier Detection (IQR Method):\")\nfor col in num_cols:\n    Q1 = train[col].quantile(0.25)\n    Q3 = train[col].quantile(0.75)\n    IQR = Q3 - Q1\n    lower_bound = Q1 - 1.5 * IQR\n    upper_bound = Q3 + 1.5 * IQR\n    outliers = train[(train[col] < lower_bound) | (train[col] > upper_bound)]\n    print(f\"Outliers in {col}: {len(outliers)}\")\n\nprint(\"\\nDecision: We are RETAINING outliers to preserve valuable information for the sentiment analysis task.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:00:12.324375Z","iopub.execute_input":"2025-12-04T12:00:12.324606Z","iopub.status.idle":"2025-12-04T12:00:12.338401Z","shell.execute_reply.started":"2025-12-04T12:00:12.324586Z","shell.execute_reply":"2025-12-04T12:00:12.337596Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Rubric Step 6: Visualizations\nWe will present at least three visualizations to gain insights into the data.","metadata":{}},{"cell_type":"code","source":"# Visualization 1: Target Distribution\nplt.figure(figsize=(8, 6))\nsns.countplot(x='sentiment', data=train)\nplt.title('Distribution of Sentiment')\nplt.xlabel('Sentiment')\nplt.ylabel('Count')\nplt.show()\n\n# Visualization 2: Top 20 Frequent Words\nall_words = ' '.join(train['phrase'].astype(str)).split()\nword_freq = Counter(all_words).most_common(20)\nwords_df = pd.DataFrame(word_freq, columns=['Word', 'Frequency'])\n\nplt.figure(figsize=(12, 6))\nsns.barplot(x='Frequency', y='Word', data=words_df)\nplt.title('Top 20 Frequent Words')\nplt.show()\n\n# Visualization 3: Correlation Heatmap of Numerical Features\nplt.figure(figsize=(8, 6))\nsns.heatmap(train[num_cols].corr(), annot=True, cmap='coolwarm')\nplt.title('Correlation Matrix of Numerical Features')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:00:12.339488Z","iopub.execute_input":"2025-12-04T12:00:12.339709Z","iopub.status.idle":"2025-12-04T12:00:13.064932Z","shell.execute_reply.started":"2025-12-04T12:00:12.339685Z","shell.execute_reply":"2025-12-04T12:00:13.064098Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Rubric Step 7: Scale Numerical Features and Encode Categorical Features\nWe will define a preprocessing pipeline that:\n1. Cleans the text data.\n2. Extracts features using TF-IDF (Word and Character n-grams).\n3. Extracts sentiment scores using VADER.\n4. Scales numerical features using MinMaxScaler.","metadata":{}},{"cell_type":"code","source":"# Text Cleaning Function\ndef clean_text(text):\n    lemmatizer = WordNetLemmatizer()\n    # Lowercase\n    text = str(text).lower()\n    # Remove special chars and numbers\n    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n    # Tokenize\n    words = text.split()\n    # Lemmatize (keeping stopwords for context like 'not')\n    words = [lemmatizer.lemmatize(word) for word in words]\n    return \" \".join(words)\n\n# Apply cleaning\ntrain['cleaned_phrase'] = train['phrase'].apply(clean_text)\ntest['cleaned_phrase'] = test['phrase'].apply(clean_text)\n\n# Custom Transformer for VADER Sentiment\nclass VaderSentimentEstimator(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        self.sia = SentimentIntensityAnalyzer()\n\n    def fit(self, X, y=None):\n        return self\n\n    def transform(self, X):\n        scores = [self.sia.polarity_scores(str(text))['compound'] for text in X]\n        return np.array(scores).reshape(-1, 1)\n\n# Define Transformers\ntext_word_transformer = TfidfVectorizer(max_features=10000, ngram_range=(1, 3), min_df=2, max_df=0.9, sublinear_tf=True)\ntext_char_transformer = TfidfVectorizer(max_features=10000, analyzer='char', ngram_range=(2, 4), min_df=2, max_df=0.9, sublinear_tf=True)\n\nvader_transformer = Pipeline(steps=[\n    ('vader', VaderSentimentEstimator()),\n    ('scaler', MinMaxScaler())\n])\n\nnumeric_transformer = Pipeline(steps=[\n    ('scaler', MinMaxScaler())\n])\n\n# Column Transformer\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('text_word', text_word_transformer, 'cleaned_phrase'),\n        ('text_char', text_char_transformer, 'cleaned_phrase'),\n        ('vader', vader_transformer, 'phrase'),\n        ('num', numeric_transformer, num_cols)\n    ])\n\n# Prepare X and y\nX = train.drop(['sentiment', 'id'], axis=1)\ny = train['sentiment']\nX_test_submission = test.drop(['id'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:00:13.065852Z","iopub.execute_input":"2025-12-04T12:00:13.066230Z","iopub.status.idle":"2025-12-04T12:00:16.278806Z","shell.execute_reply.started":"2025-12-04T12:00:13.066184Z","shell.execute_reply":"2025-12-04T12:00:16.278043Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Rubric Step 9: Hyperparameter Tuning\nWe will perform hyperparameter tuning on 3 different models. For demonstration speed, we will use a subset of the data.","metadata":{}},{"cell_type":"code","source":"print(\"Hyperparameter Tuning on 3 Models (using subset for speed)...\")\nX_subset = X.iloc[:1500]\ny_subset = y.iloc[:1500]\n\n# 1. Logistic Regression Tuning\nprint(\"1. Tuning Logistic Regression...\")\nparam_grid_lr = {'classifier__C': [0.1, 1, 10]}\npipeline_lr = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', LogisticRegression(max_iter=3000, random_state=42))])\ngrid_lr = GridSearchCV(pipeline_lr, param_grid_lr, cv=3, scoring='accuracy', n_jobs=1)\ngrid_lr.fit(X_subset, y_subset)\nprint(f\"Best LR Params: {grid_lr.best_params_}, Score: {grid_lr.best_score_:.4f}\")\n\n# 2. Random Forest Tuning\nprint(\"2. Tuning Random Forest...\")\nparam_grid_rf = {'classifier__n_estimators': [100, 200], 'classifier__max_depth': [10, 20]}\npipeline_rf = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', RandomForestClassifier(random_state=42))])\ngrid_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=3, scoring='accuracy', n_jobs=1)\ngrid_rf.fit(X_subset, y_subset)\nprint(f\"Best RF Params: {grid_rf.best_params_}, Score: {grid_rf.best_score_:.4f}\")\n\n# 3. Multinomial NB Tuning\nprint(\"3. Tuning Multinomial NB...\")\nparam_grid_mnb = {'classifier__alpha': [0.1, 0.5, 1.0]}\npipeline_mnb = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', MultinomialNB())])\ngrid_mnb = GridSearchCV(pipeline_mnb, param_grid_mnb, cv=3, scoring='accuracy', n_jobs=1)\ngrid_mnb.fit(X_subset, y_subset)\nprint(f\"Best MNB Params: {grid_mnb.best_params_}, Score: {grid_mnb.best_score_:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:00:16.280632Z","iopub.execute_input":"2025-12-04T12:00:16.281108Z","iopub.status.idle":"2025-12-04T12:00:54.981481Z","shell.execute_reply.started":"2025-12-04T12:00:16.281089Z","shell.execute_reply":"2025-12-04T12:00:54.980791Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Rubric Step 8: Model Building (at least 7 models)\nWe will train and evaluate 7 different models using Cross-Validation.","metadata":{}},{"cell_type":"code","source":"models = {\n    'Logistic Regression': LogisticRegression(C=1.0, max_iter=3000, random_state=42),\n    'Linear SVC': LinearSVC(C=0.5, random_state=42, dual=True, max_iter=3000),\n    'Multinomial NB': MultinomialNB(alpha=0.5),\n    'Random Forest': RandomForestClassifier(n_estimators=300, max_depth=None, random_state=42),\n    'Ridge Classifier': RidgeClassifier(random_state=42, solver='lsqr'),\n    'XGBoost': XGBClassifier(n_estimators=200, learning_rate=0.1, random_state=42, eval_metric='logloss'),\n    'LightGBM': LGBMClassifier(n_estimators=200, learning_rate=0.05, random_state=42, verbose=-1)\n}\n\nresults = {}\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\nprint(\"Training 7 Models with Cross-Validation...\")\nfor name, model in models.items():\n    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                               ('classifier', model)])\n    scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy', n_jobs=1)\n    results[name] = scores.mean()\n    print(f\"{name}: Mean CV Accuracy = {scores.mean():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:00:54.982404Z","iopub.execute_input":"2025-12-04T12:00:54.982656Z","iopub.status.idle":"2025-12-04T12:26:55.440130Z","shell.execute_reply.started":"2025-12-04T12:00:54.982635Z","shell.execute_reply":"2025-12-04T12:26:55.439463Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Rubric Step 10: Comparison of Model Performances\nWe will compare the performance of the models and build a Voting Ensemble for the final submission.","metadata":{}},{"cell_type":"code","source":"results_df = pd.DataFrame(list(results.items()), columns=['Model', 'Accuracy']).sort_values(by='Accuracy', ascending=False)\nprint(\"Model Comparison Table:\")\nprint(results_df)\n\n# Visualize Comparison\nplt.figure(figsize=(10, 6))\nsns.barplot(x='Accuracy', y='Model', data=results_df)\nplt.title('Model Accuracy Comparison')\nplt.xlim(0, 1.0)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:26:55.441237Z","iopub.execute_input":"2025-12-04T12:26:55.441481Z","iopub.status.idle":"2025-12-04T12:26:55.634666Z","shell.execute_reply.started":"2025-12-04T12:26:55.441465Z","shell.execute_reply":"2025-12-04T12:26:55.634171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Building Voting Ensemble (Soft Voting) with Top Performers\nprint(\"Building Voting Ensemble...\")\n\nestimators = [\n    ('lr', Pipeline([('preprocessor', preprocessor), ('clf', LogisticRegression(C=1, max_iter=3000))])),\n    ('svc', Pipeline([('preprocessor', preprocessor), ('clf', CalibratedClassifierCV(LinearSVC(C=0.5, dual=True, max_iter=3000), cv=3))])),\n    ('mnb', Pipeline([('preprocessor', preprocessor), ('clf', MultinomialNB(alpha=0.5))]))\n]\n\nvoting_clf = VotingClassifier(estimators=estimators, voting='soft', n_jobs=1)\n\n# Evaluate Ensemble on Hold-out set\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\nvoting_clf.fit(X_train, y_train)\nval_preds = voting_clf.predict(X_val)\nensemble_acc = accuracy_score(y_val, val_preds)\nprint(f\"Voting Ensemble Validation Accuracy: {ensemble_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:26:55.635253Z","iopub.execute_input":"2025-12-04T12:26:55.635435Z","iopub.status.idle":"2025-12-04T12:27:08.174561Z","shell.execute_reply.started":"2025-12-04T12:26:55.635419Z","shell.execute_reply":"2025-12-04T12:27:08.173777Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Final Submission\nWe will retrain the ensemble model on the full training data and generate predictions for the test set.","metadata":{}},{"cell_type":"code","source":"print(\"Retraining Final Model on Full Data...\")\nvoting_clf.fit(X, y)\n\nprint(\"Generating Predictions for Test Set...\")\npredictions = voting_clf.predict(X_test_submission)\n\nsubmission_df = pd.DataFrame({'id': test['id'], 'sentiment': predictions})\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission saved to 'submission.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T12:27:08.175495Z","iopub.execute_input":"2025-12-04T12:27:08.176083Z","iopub.status.idle":"2025-12-04T12:27:24.894633Z","shell.execute_reply.started":"2025-12-04T12:27:08.176064Z","shell.execute_reply":"2025-12-04T12:27:24.893791Z"}},"outputs":[],"execution_count":null}]}